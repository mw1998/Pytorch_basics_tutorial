{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatsAndDogsDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.2510, 0.2510, 0.1961,  ..., 0.5255, 0.5882, 0.5216],\n",
       "           [0.2275, 0.2392, 0.2000,  ..., 0.5804, 0.6980, 0.5725],\n",
       "           [0.3137, 0.2902, 0.2627,  ..., 0.5490, 0.5647, 0.5765],\n",
       "           ...,\n",
       "           [0.5098, 0.3725, 0.2392,  ..., 0.1529, 0.1804, 0.0980],\n",
       "           [0.5882, 0.4471, 0.2510,  ..., 0.1843, 0.1490, 0.5490],\n",
       "           [0.5686, 0.4510, 0.2706,  ..., 0.1216, 0.5020, 0.7686]],\n",
       " \n",
       "          [[0.2118, 0.2118, 0.1569,  ..., 0.4980, 0.5529, 0.4863],\n",
       "           [0.1765, 0.1882, 0.1529,  ..., 0.5529, 0.6627, 0.5255],\n",
       "           [0.2588, 0.2353, 0.1961,  ..., 0.5137, 0.5176, 0.5294],\n",
       "           ...,\n",
       "           [0.4784, 0.3333, 0.2000,  ..., 0.1137, 0.1412, 0.0627],\n",
       "           [0.5608, 0.4196, 0.2118,  ..., 0.1373, 0.1059, 0.5059],\n",
       "           [0.5412, 0.4235, 0.2314,  ..., 0.0745, 0.4588, 0.7294]],\n",
       " \n",
       "          [[0.2078, 0.2078, 0.1529,  ..., 0.4353, 0.4941, 0.4196],\n",
       "           [0.2039, 0.2157, 0.1686,  ..., 0.4902, 0.5961, 0.4627],\n",
       "           [0.3176, 0.2941, 0.2588,  ..., 0.4471, 0.4549, 0.4667],\n",
       "           ...,\n",
       "           [0.5216, 0.3686, 0.2353,  ..., 0.1569, 0.1725, 0.0824],\n",
       "           [0.5922, 0.4510, 0.2471,  ..., 0.1843, 0.1294, 0.5216],\n",
       "           [0.5725, 0.4549, 0.2627,  ..., 0.1137, 0.4824, 0.7333]]],\n",
       " \n",
       " \n",
       "         [[[0.1529, 0.1529, 0.1529,  ..., 0.7333, 0.8196, 0.8000],\n",
       "           [0.1647, 0.1569, 0.1569,  ..., 0.7373, 0.7961, 0.7922],\n",
       "           [0.1608, 0.1529, 0.1569,  ..., 0.7333, 0.7765, 0.7922],\n",
       "           ...,\n",
       "           [0.1137, 0.1098, 0.0980,  ..., 0.1843, 0.1725, 0.1529],\n",
       "           [0.1255, 0.1176, 0.1059,  ..., 0.1176, 0.1412, 0.1608],\n",
       "           [0.1373, 0.1294, 0.1098,  ..., 0.1098, 0.1608, 0.1804]],\n",
       " \n",
       "          [[0.1725, 0.1725, 0.1686,  ..., 0.7255, 0.8000, 0.7765],\n",
       "           [0.1843, 0.1765, 0.1725,  ..., 0.7294, 0.7765, 0.7686],\n",
       "           [0.1804, 0.1725, 0.1725,  ..., 0.7216, 0.7529, 0.7647],\n",
       "           ...,\n",
       "           [0.1059, 0.1020, 0.0902,  ..., 0.1333, 0.1216, 0.1020],\n",
       "           [0.1176, 0.1098, 0.0980,  ..., 0.0667, 0.0902, 0.1098],\n",
       "           [0.1176, 0.1098, 0.0902,  ..., 0.0588, 0.1098, 0.1294]],\n",
       " \n",
       "          [[0.1490, 0.1569, 0.1647,  ..., 0.6353, 0.6824, 0.6431],\n",
       "           [0.1608, 0.1608, 0.1686,  ..., 0.6471, 0.6627, 0.6431],\n",
       "           [0.1569, 0.1569, 0.1686,  ..., 0.6471, 0.6510, 0.6510],\n",
       "           ...,\n",
       "           [0.1176, 0.1137, 0.1020,  ..., 0.1098, 0.0980, 0.0784],\n",
       "           [0.1294, 0.1216, 0.1098,  ..., 0.0431, 0.0588, 0.0784],\n",
       "           [0.1333, 0.1255, 0.1059,  ..., 0.0353, 0.0784, 0.0980]]]]),\n",
       " tensor([0, 0])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CatsAndDogsDataset(csv_file='dataset\\cats_dogs\\cats_dogs.csv', \\\n",
    "                             root_dir='dataset\\cats_dogs\\cats_dogs_resized', \\\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [7, 3])\n",
    "# print(train_set[0])\n",
    "# print(test_set[0])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=2, shuffle=True)\n",
    "# print(len(train_loader))\n",
    "# print(len(test_loader))\n",
    "next(iter(test_loader))\n",
    "next(iter(test_loader))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bea151495e21b09669b579db65fdfd1623fa1cb64926cd75da5b5ecb0779b291"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('d2l': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
